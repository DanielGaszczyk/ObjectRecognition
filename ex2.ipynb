{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected features: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EX1\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import sys\n",
    "import math\n",
    "\n",
    "\n",
    "def draw_corners(image, corners_map):\n",
    "    \"\"\"Draw a point for each possible corner.\"\"\"\n",
    "    for corner in corners_map:\n",
    "        cv.circle(image,(corner[1], corner[0]),5,(255,0,0),1)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\n",
    "def moravec(image, threshold = 100):\n",
    "    \"\"\"Moravec's corner detection for each pixel of the image.\"\"\"\n",
    "\n",
    "    corners = []\n",
    "    xy_shifts = [(1, 0), (1, 1), (0, 1), (-1, 1)]\n",
    "    width, height = image.shape[:2]\n",
    "    for y in range(1, height-1):\n",
    "        for x in range(1, width-1):\n",
    "            # Look for local maxima in min(E) above threshold:\n",
    "            E = 100000\n",
    "            for shift in xy_shifts:\n",
    "                diff = int(image[x + shift[0], y + shift[1]])\n",
    "                diff = int(diff - image[x, y])\n",
    "                diff = int(diff * diff)\n",
    "\n",
    "                if (diff < E):\n",
    "                    E = diff\n",
    "            if E > threshold:\n",
    "                corners.append((x, y))\n",
    "\n",
    "    print(\"Number of detected features: \"+str(len(corners)))\n",
    "    return corners\n",
    "\n",
    "\n",
    "\n",
    "threshold = 1000\n",
    "\n",
    "img = cv.imread('PST_1920x1088_cam4.png')\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "corners = moravec(gray, threshold)\n",
    "draw_corners(img, corners)\n",
    "cv.imwrite('moravec_'  + str(threshold)+'.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected features: 77851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EX2\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import sys\n",
    "import math\n",
    "\n",
    "\n",
    "def draw_corners(image, corners_map):\n",
    "    \"\"\"Draw a point for each possible corner.\"\"\"\n",
    "    for corner in corners_map:\n",
    "        cv.circle(image,(corner[1], corner[0]),5,(255,0,0),1)\n",
    "\n",
    "\n",
    "\n",
    "def harris(image, threshold = 100000000, sigma = 1.5, k = 0.04):\n",
    "    \"\"\"Harris' corner detection for each pixel of the image.\"\"\"\n",
    "\n",
    "    corners = []\n",
    "    width, height = image.shape[:2]\n",
    "\t\n",
    "    # Calculate gradients:\n",
    "    X2 = [[0] * width for y in range(height)]\n",
    "    Y2 = [[0] * width for y in range(height)]\n",
    "    XY = [[0] * width for y in range(height)]\n",
    "\t\n",
    "    for y in range(1, height-1):\n",
    "        for x in range(1, width-1):\n",
    "            X = int(image[x + 1, y]) - int(image[x - 1, y])\n",
    "            Y = int(image[x, y + 1]) - int(image[x, y - 1])\n",
    "\n",
    "            X2[y][x] = int(X * X)\n",
    "            Y2[y][x] = int(Y * Y)\n",
    "            XY[y][x] = int(X * Y)\n",
    "\n",
    "    # Gaussian 3x3:\n",
    "    G = [[0,0,0], [0,0,0], [0,0,0]]\n",
    "    for y in range(3):\n",
    "        for x in range(3):\n",
    "            u, v = x-1, y-1\n",
    "            G[y][x] = (math.exp(-(u*u + v*v)/(2*sigma*sigma)))\n",
    "\n",
    "    # Convolve with Gaussian 3x3:\n",
    "    A = [[0] * width for y in range(height)]\n",
    "    B = [[0] * width for y in range(height)]\n",
    "    C = [[0] * width for y in range(height)]\n",
    "\t\n",
    "    for y in range(1, height-1):\n",
    "        for x in range(1, width-1):\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    u, v = j-1, i-1\n",
    "                    A[y][x] = A[y][x] + X2[y + v][x + u] * G[i][j]\n",
    "                    B[y][x] = B[y][x] + Y2[y + v][x + u] * G[i][j]\n",
    "                    C[y][x] = C[y][x] + XY[y + v][x + u] * G[i][j]\n",
    "    del X2, Y2, XY\n",
    "\n",
    "    # Harris Response Function:\n",
    "    R = [[0] * width for y in range(height)]\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            a, b, c = A[y][x], B[y][x], C[y][x]\n",
    "            Tr = a + b\n",
    "            Det = a * b - c * c\n",
    "            R[y][x] = Det - k * Tr * Tr\n",
    "    del A, B, C\n",
    "\n",
    "    # Suppress Non-Maximum Points:\n",
    "    for y in range(1, height-1):\n",
    "        for x in range(1, width-1):\n",
    "            maximum = True\n",
    "            for dy in (-1, 0, 1):\n",
    "                for dx in (-1, 0, 1):\n",
    "                    if R[y][x] < R[y + dy][x + dx]:\n",
    "                        maximum = False \n",
    "            if maximum and R[y][x] > threshold:\n",
    "                corners.append((x, y))\n",
    "            \n",
    "\t\t\t\n",
    "    print(\"Number of detected features: \"+str(len(corners)))\n",
    "    return corners\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "threshold = 1000\n",
    "\n",
    "\n",
    "\n",
    "img = cv.imread('PST_1920x1088_cam4.png')\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "corners = harris(gray, threshold)\n",
    "draw_corners(img, corners)\n",
    "cv.imwrite('harris_'  + str(threshold)+'.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected features: 598\n",
      "Number of detected features: 611\n",
      "361.20199909921956 PSNR\n",
      "Number of detected features: 33\n",
      "Number of detected features: 159\n",
      "361.20199909921956 PSNR\n",
      "Number of detected features: 3\n",
      "Number of detected features: 34\n",
      "361.20199909921956 PSNR\n",
      "Number of detected features: 0\n",
      "Number of detected features: 3\n",
      "361.20199909921956 PSNR\n",
      "Number of detected features: 0\n",
      "Number of detected features: 0\n",
      "361.20199909921956 PSNR\n",
      "Number of detected features: 0\n",
      "Number of detected features: 0\n",
      "361.20199909921956 PSNR\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3602/2967690108.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mcorners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoravec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mdraw_corners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'moravec_'\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3602/154580706.py\u001b[0m in \u001b[0;36mmoravec\u001b[0;34m(image, threshold)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mshift\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxy_shifts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#TASK 1 \n",
    "#Task 1: Prepare the code for a programme that will determine the dependence of the number\n",
    "#of feature points determined by Moravec and Harris detectors as a function of the change in\n",
    "#image quality. Filter the input images with a low pass filter. Put the value of PSNR on the x axis\n",
    "#and the value of the number of landmarks on the y axis.\n",
    "\n",
    "#EX2\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import sys\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "abc=0\n",
    "\n",
    "threshold = 1000\n",
    "harrisList = []\n",
    "moraviec = []\n",
    "psnr = []\n",
    "\n",
    "for x in range(1,12,2):\n",
    "    img = cv.imread('PST_1920x1088_cam4.png')\n",
    "    gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    dst = cv.GaussianBlur(gray,(x,x),0,0,0)\n",
    "    corners = moravec(dst, threshold)\n",
    "    draw_corners(img, corners)\n",
    "    cv.imwrite('moravec_'  + str(threshold)+'.png',img)\n",
    "    moraviec.append(len(corners))\n",
    "\n",
    "    thresholdHarris = 100000000\n",
    "    img2 = cv.imread('PST_1920x1088_cam4.png')\n",
    "    gray2 = cv.cvtColor(img2,cv.COLOR_BGR2GRAY)\n",
    "    dst2 = cv.GaussianBlur(gray2,(x,x),0,0,0)\n",
    "    corners2 = harris(dst2, thresholdHarris)\n",
    "    draw_corners(img2, corners2)\n",
    "    cv.imwrite('harris_'  + str(thresholdHarris)+'.png',img2)\n",
    "    harrisList.append(len(corners2))\n",
    "\n",
    "    print(cv.PSNR(dst,dst2),\"PSNR\")\n",
    "    psnr.append(cv.PSNR(dst,dst2))\n",
    "\n",
    "plt.plot(psnr,moraviec)\n",
    "plt.plot(psnr,harrisList)\n",
    "plt.ylabel('PSNR vs Landmarks number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX3\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "filename = 'chessboard.jpg'\n",
    "img = cv2.imread(filename)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv2.dilate(dst,None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "\n",
    "rows,cols = img.shape[1],img.shape[0]\n",
    "# you can use other parameters\n",
    "#M = cv2.getRotationMatrix2D((cols/2,rows/2), 45, 1);\n",
    "#img = cv2.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "cv2.imshow('dst',img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0] global /tmp/pip-req-build-agffqapq/opencv/modules/highgui/src/window.cpp (703) createTrackbar UI/Trackbar(Prog: @Obraz zrodlowy): Using 'value' pointer is unsafe and deprecated. Use NULL as value pointer. To fetch trackbar value setup callback.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EX4\n",
    "from __future__ import print_function\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import argparse\n",
    "source_window = 'Obraz zrodlowy'\n",
    "corners_window = 'Wyznaczone narozniki'\n",
    "max_thresh = 255\n",
    "\n",
    "def demo(val):\n",
    "    thresh = val\n",
    "\n",
    "    # Parametry detektora\n",
    "    blockSize = 2\n",
    "    apertureSize = 3\n",
    "    k = 0.04\n",
    "    \n",
    "    # Wyznaczanie naroznikow\n",
    "    dst = cv.cornerHarris(src_gray, blockSize, apertureSize, k)\n",
    "    \n",
    "    \n",
    "    # Normalizacja\n",
    "    dst_norm = np.empty(dst.shape, dtype=np.float32)\n",
    "    cv.normalize(dst, dst_norm, alpha=0, beta=255, norm_type=cv.NORM_MINMAX)\n",
    "    dst_norm_scaled = cv.convertScaleAbs(dst_norm)\n",
    "    \n",
    "    \n",
    "    # Wykreślanie okręgów wokół narożników \n",
    "    for i in range(dst_norm.shape[0]):\n",
    "        for j in range(dst_norm.shape[1]):\n",
    "            if int(dst_norm[i,j]) > thresh:\n",
    "                cv.circle(dst_norm_scaled, (j,i), 5, (0), 2)\n",
    "                \n",
    "    # Wyświetlanie wyników\n",
    "    cv.namedWindow(corners_window)\n",
    "    cv.imshow(corners_window, dst_norm_scaled)\n",
    "    \n",
    "    \n",
    "# Ładowanie danych wejściowych\n",
    "src = cv.imread('building.jpg')\n",
    "if src is None:\n",
    "    print('Nie można wczytać obrazka:', args.input)\n",
    "    exit(0)\n",
    "src_gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Tworzenie okna i suwaka dla parametru threshold\n",
    "cv.namedWindow(source_window)\n",
    "thresh = 100 # początkowa wartość progu\n",
    "cv.createTrackbar('Prog: ', source_window, thresh, max_thresh, demo)\n",
    "cv.imshow(source_window, src)\n",
    "demo(thresh)\n",
    "cv.waitKey()\n",
    "\n",
    "# thresholding parameter directly influence on number of marked cornetrs. Lower threshold equal more marked corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX5\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img = cv2.imread('building.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('chessboard.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "\n",
    "corners = cv2.goodFeaturesToTrack(img, 200, 0.01, 2)\n",
    "corners = np.int0(corners)\n",
    "\n",
    "corners2 = cv2.goodFeaturesToTrack(img2, 200, 0.01, 2)\n",
    "corners2 = np.int0(corners2)\n",
    "        \n",
    "for i in corners:\n",
    "    x,y = i.ravel()\n",
    "    cv2.circle(img,(x,y),3,1,-1)\n",
    "    \n",
    "      \n",
    "for z in corners2:\n",
    "    x,y = z.ravel()\n",
    "    cv2.circle(img2,(x,y),3,1,-1)\n",
    "    \n",
    "\n",
    "cv2.imshow('dobre narozniki',img)\n",
    "\n",
    "cv2.imshow('dobre narozniki2',img2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Note the effect of the thresholding parameter on the number of corners determined.\n",
    "#How does the point detection performance differ from the metric used in the Harris\n",
    "#detector for the same images? In addition to the building.jpg, image, use another\n",
    "#example image.\n",
    "\n",
    "# thresholding parameter directly influence on number of marked cornetrs. Lower threshold equal more marked corners. We have 3 parameters\n",
    "#that have directly influence on this number - maxCorners, qualityLevel, minDistance. Max corners can block numbers of detected cornes\n",
    "#minDistance limit number of detected corners near each other, qualityLevel Parameter characterizing the minimal accepted quality \n",
    "# of image corners. The parameter value is multiplied by the best corner quality measure, which is the minimal eigenvalue \n",
    "# (see #cornerMinEigenVal ) or the Harris function response (see #cornerHarris ). The corners with the quality measure less \n",
    "# than the product are rejected. For example, if the best corner has the quality measure = 1500, and the qualityLevel=0.01 , \n",
    "# then all the corners with the quality measure less than 15 are rejected.\n",
    "# Harris detector in result gives more points than Moraviec in the same thershold.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "#EX5 rotated\n",
    "\n",
    "#Based on task 1, check how the number of points detected by the Shi-Tomasi detector\n",
    "#changes as a function of changing the image angle. Show and comment on the\n",
    "#relationship between number of points and rotation.\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('chessboard.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "rows,cols = img.shape[1],img.shape[0]\n",
    "# you can use other parameters\n",
    "#M = cv2.getRotationMatrix2D((cols/2,rows/2), 45, 1);\n",
    "#img = cv2.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "corners = cv2.goodFeaturesToTrack(img, 200, 0.01, 1)\n",
    "corners = np.int0(corners)\n",
    "        \n",
    "for i in corners:\n",
    "    x,y = i.ravel()\n",
    "    cv2.circle(img,(x,y),3,5,-1)\n",
    "\n",
    "    \n",
    "print(len(corners))\n",
    "cv2.imshow('dobre narozniki',img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Rotated images gives in results less points than straight image"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
